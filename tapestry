#!/usr/bin/env python3

__version__=0.1

import argparse, sys, os, errno, gzip, pysam
import logging as log

import plotly
import plotly.graph_objs as go

from functools import partial
from shutil import copyfile
from multiprocessing import Pool
from Bio import SeqIO
from statistics import mean
from plumbum.cmd import minimap2, mosdepth, samtools, nucmer
from plumbum.cmd import head, cut, zgrep

#http://code.activestate.com/recipes/577452-a-memoize-decorator-for-instance-methods/
class memoize(object):
    """cache the return value of a method
    
    This class is meant to be used as a decorator of methods. The return value
    from a given method invocation will be cached on the instance whose method
    was invoked. All arguments passed to a method decorated with memoize must
    be hashable.
    
    If a memoized method is invoked directly on its class the result will not
    be cached. Instead the method will be invoked like a static method:
    class Obj(object):
        @memoize
        def add_to(self, arg):
            return self + arg
    Obj.add_to(1) # not enough arguments
    Obj.add_to(1, 2) # returns 3, result is not cached
    """
    def __init__(self, func):
        self.func = func
    def __get__(self, obj, objtype=None):
        if obj is None:
            return self.func
        return partial(self, obj)
    def __call__(self, *args, **kw):
        obj = args[0]
        try:
            cache = obj.__cache
        except AttributeError:
            cache = obj.__cache = {}
        key = (self.func, args[1:], frozenset(kw.items()))
        try:
            res = cache[key]
        except KeyError:
            res = cache[key] = self.func(*args, **kw)
        return res


class Assembly:
    def __init__(self, assemblyfile, readfile, outdir, threads):
        self.assemblyfile = assemblyfile
        self.readfile = readfile
        self.outdir = outdir
        self.threads = threads

        self.setup_output()
        self.prepare_genome()
        self.contigs = self.load_genome()

        if self.readfile:
            self.align_reads_to_assembly()
            self.align_contigs_to_assembly()
        else:
            log.warning("No read file provided (-r), will skip read metrics")

    def setup_output(self):
        try:
            os.mkdir(self.outdir)
            log.info(f"Created output directory {self.outdir}")
        except OSError as exc:
            if exc.errno == errno.EEXIST:
                log.warning(f"Output directory {self.outdir} found, will use existing analysis files if present, but overwrite reports")
            else:
                raise

    def prepare_genome(self):
        if os.path.exists(f"{self.outdir}/assembly.fasta"):
            log.info(f"Will use existing {self.outdir}/assembly.fasta file")
        else:
            try:
                log.info(f"Copying assembly to {self.outdir}")
                copyfile(self.assemblyfile, f"{self.outdir}/assembly.fasta") 
            except:
                 log.error(f"Can't copy assembly to {self.outdir}")
                 sys.exit()

        if os.path.exists(f"{self.outdir}/assembly.fasta.fai"):
           log.info(f"Will use existing {self.outdir}/assembly.fasta.fai")
        else:
            try:
                log.info(f"Indexing assembly")
                samtools("faidx", f"{self.outdir}/assembly.fasta")
            except:
                log.error(f"Can't index assembly!")
                sys.exit()

    def load_genome(self):
        contigs = []
        try:
            log.info(f"Loading genome assembly")
            for rec in SeqIO.parse(open(f"{self.outdir}/assembly.fasta", 'r'), "fasta"):
                rec.seq = rec.seq.upper()
                contigs.append(Contig(rec.id, rec.seq, self.outdir))
        except IOError:
            log.error(f"Can't load assembly from file {self.assemblyfile}!")
            sys.exit()


        return contigs

    def align_reads_to_assembly(self):
        if os.path.exists(f"{self.outdir}/reads_assembly.bam"):
            log.info(f"Will use existing {self.outdir}/reads_assembly.bam")
        else:
            log.info(f"Aligning reads {os.path.abspath(self.readfile)} to assembly")

            # samtools uses threads-1 because -@ specifies additional threads and defaults to 0
            try:
                align_reads = minimap2["-xmap-ont", "-a", f"-t{self.threads}", \
                                       f"{self.outdir}/assembly.fasta", self.readfile] | \
                              samtools["sort", f"-@{self.threads-1}", \
                                       f"-o{self.outdir}/reads_assembly.bam"]
                align_reads()
                samtools("index", f"-@{self.threads-1}", f"{self.outdir}/reads_assembly.bam")
            except:
                log.error(f"Failed to align {self.readfile} to {self.outdir}/assembly.fasta")
                sys.exit()

        self.run_mosdepth("reads_assembly")

    def align_contigs_to_assembly(self):
        if os.path.exists(f"{self.outdir}/contigs_assembly.bam"):
            log.info(f"Will use existing {self.outdir}/contigs_assembly.bam")
        else:
            log.info("Aligning assembly to itself...")
            try:
                 nucmer(f"-t{self.threads}", f"--sam-short={self.outdir}/contigs_assembly.sam", \
                        f"{self.outdir}/assembly.fasta", f"{self.outdir}/assembly.fasta")
                 nucmer_to_bam = samtools["view", f"-ht{self.outdir}/assembly.fasta.fai", \
                                          f"{self.outdir}/contigs_assembly.sam"] | \
                                 samtools["sort", f"-@{self.threads-1}", \
                                          f"-o{self.outdir}/contigs_assembly.bam"]
                 nucmer_to_bam()
                 samtools("index", f"-@{self.threads-1}", f"{self.outdir}/contigs_assembly.bam")
                 os.remove(f"{self.outdir}/contigs_assembly.sam")
            except:
                 log.error(f"Failed to align {self.outdir}/assembly.fasta to itself")
                 sys.exit()

        self.run_mosdepth("contigs_assembly")

    def run_mosdepth(self, filestub):
        if os.path.exists(f"{self.outdir}/{filestub}.regions.bed.gz"):
            log.info(f"Will use existing {filestub} mosdepth output")
            return

        log.info(f"Running mosdepth for {filestub}...")
        
        try:
            mosdepth(f"-t{self.threads}", "-b1000", "-n", \
                     f"{self.outdir}/{filestub}", \
                     f"{self.outdir}/{filestub}.bam")
        except:
            log.error(f"Failed to run mosdepth for {self.outdir}/{filestub}.bam")
            sys.exit()
    
    def report(self):
        try:
            with open(f"{self.outdir}/report.txt", 'wt') as reportfile:
                with Pool(self.threads) as p:
                    for report in p.map(contig_report, self.contigs):
                        print(report, file=reportfile)
        except IOError:
            log.error(f"Could not open report file {self.outdir}/report.txt")

# Defining contig report at top level rather than in class so it works with multiprocessing
def contig_report(contig):
    return f"{contig.name}\t{len(contig)}\t{contig.depth('reads')}\t{contig.depth('contigs')}\t{contig.num_alignments()}"
            
class Contig:
    def __init__(self, name, seq, outdir):
        self.name = name
        self.seq = seq
        self.outdir = outdir

    def __len__(self):
        return len(self.seq)

    @memoize
    def depth(self, mapped):
        depths = []
        for line in zgrep(f"^{self.name}", f"{self.outdir}/{mapped}_assembly.regions.bed.gz").split('\n')[:-1]:
            depths.append(float(line.split('\t')[3]))
        return f"{mean(depths):.1f}"

    @memoize
    def num_alignments(self):
        bam = pysam.AlignmentFile(f"{self.outdir}/reads_assembly.bam", 'rb')
        alignments = 0
        for aln in bam.fetch(self.name):
            alignments += 1
        return alignments

def set_verbosity(verbosity):
    if verbosity == 1:
        log.getLogger().setLevel(log.INFO)
    elif verbosity > 1:
        log.getLogger().setLevel(log.DEBUG)
    else:
        log.getLogger().setLevel(log.WARN)


def versions(verbosity):
    log.info(f"Tapestry version {__version__}")
    
    log.getLogger().setLevel(log.INFO) # Suppress plumbum DEBUG messages
    debug = "Dependencies\n"

    debug += f"minimap2\t{minimap2('--version').rstrip()}\t{minimap2}\n"

    samtools_version = samtools['--version'] | head['-n 1'] | cut['-d ', '-f2']
    debug += f"samtools\t{samtools_version().rstrip()}\t{samtools}\n"
    
    mosdepth_version = mosdepth['-h'] | head['-n 1'] | cut['-d ', '-f2']
    debug += f"mosdepth\t{mosdepth_version().rstrip()}\t{mosdepth}\n"
    
    debug += f"nucmer\t{nucmer('-V').rstrip()}\t{nucmer}\n" 

    set_verbosity(verbosity) # Reset logger now plumbum commands are done

    log.debug(debug.expandtabs(15))


def get_args():
    parser = argparse.ArgumentParser(description="Tapestry: assess genome assembly quality")

    parser.add_argument('-a', '--assembly', help="filename of assembly in FASTA format", type=str, required=True)
    parser.add_argument('-r', '--reads', help="filename of reads in gzipped FASTQ format", type=str)
    parser.add_argument('-t', '--threads', help="number of parallel threads to use", type=int, default=1)
    parser.add_argument('-o', '--output', help="directory to write output, default tapestry_output", type=str, default="tapestry_output")
    parser.add_argument('-v', '--verbose', help="report on progress", action="count", default=0)
    parser.add_argument('-V', '--version', help="report version number and exit", action="store_true") 

    args = parser.parse_args()

    if args.version:
        versions(args.verbose)
        sys.exit()

    log.basicConfig(format="%(levelname)s: %(message)s")

    set_verbosity(args.verbose)

    if args.threads<1:
        log.error("Threads must be at least 1")
        sys.exit()

    return args



if __name__ == '__main__':

    args = get_args()

    versions(args.verbose)

    assembly = Assembly(args.assembly, args.reads, args.output, args.threads)

    assembly.report()

    log.info("Done")
